# üöÄ Como Executar o Projeto

## üìã Pr√©-requisitos

- Docker e Docker Compose instalados
- Git (para clonar o reposit√≥rio)
- Pelo menos 4GB de RAM livre
- Conex√£o com internet (para download de modelos AI)

## ‚ö° Execu√ß√£o R√°pida

```bash
# 1. Navegar para o diret√≥rio do projeto
cd /home/capecci/ImagesProcess/imagesProccess

# 2. Executar todos os servi√ßos
docker-compose up --build

# 3. Aguardar inicializa√ß√£o (primeira vez demora mais para baixar modelos)
# Logs indicar√£o quando todos os servi√ßos estiverem prontos

# 4. Acessar a aplica√ß√£o
# Frontend: http://localhost
# Backend API: http://localhost/api
# AI Service: http://localhost/ai
# Direct AI Service: http://localhost:5000
```

## üîß Configura√ß√£o Detalhada

### 1. Estrutura de Portas
- **Nginx (Proxy)**: `80` e `443`
- **Frontend Angular**: `4200` (interno)
- **Backend Node.js**: `3001` (interno)  
- **AI Service Python**: `5000` (interno + externa)

### 2. Vari√°veis de Ambiente

#### Backend (.env)
```bash
NODE_ENV=production
PORT=3001
AI_SERVICE_URL=http://ai-service:5000
FRONTEND_URL=http://localhost:4200
```

#### AI Service
```bash
PORT=5000
MODEL=u2net
ENVIRONMENT=production
```

### 3. Volumes Docker
- `ai-models`: Cache de modelos AI (evita re-download)
- C√≥digo fonte montado para desenvolvimento

## üìä Testando a API

### Health Checks
```bash
# Backend
curl http://localhost/api/health

# AI Service  
curl http://localhost/ai/health

# Stats do AI Service
curl http://localhost/ai/stats
```

### Upload de Imagem
```bash
# Via curl (teste)
curl -X POST \
  http://localhost/api/images/remove-background \
  -H "Content-Type: multipart/form-data" \
  -F "image=@/path/to/your/image.jpg"
```

## üê≥ Comandos Docker √öteis

```bash
# Parar todos os servi√ßos
docker-compose down

# Rebuild apenas um servi√ßo  
docker-compose up --build ai-service

# Ver logs de um servi√ßo espec√≠fico
docker-compose logs -f backend

# Limpar volumes (re-download modelos)
docker-compose down -v

# Executar em background
docker-compose up -d
```

## üîç Debugging

### Logs dos Servi√ßos
```bash
# Todos os logs
docker-compose logs -f

# Apenas AI Service
docker-compose logs -f ai-service

# Apenas Backend
docker-compose logs -f backend
```

### Problemas Comuns

**1. AI Service demora para inicializar**
- Primeira execu√ß√£o baixa modelos (~1-2GB)
- Aguardar mensagem "Model loaded successfully!"

**2. Out of Memory**
- Aumentar RAM dispon√≠vel para Docker
- Ou usar modelo menor: `u2netp` ao inv√©s de `u2net`

**3. Permiss√µes de arquivo**
```bash
sudo chown -R $USER:$USER .
```

**4. Porta em uso**
```bash
# Verificar portas ocupadas
sudo netstat -tulpn | grep :80
sudo netstat -tulpn | grep :5000
```

## üöÄ Deploy em Produ√ß√£o

### 1. Configura√ß√µes de Produ√ß√£o
- Configurar dom√≠nio no Nginx
- Adicionar certificados SSL
- Ajustar limites de upload
- Configurar monitoring

### 2. Vari√°veis de Ambiente Produ√ß√£o
```bash
# .env.production
NODE_ENV=production
AI_SERVICE_URL=http://ai-service:5000
FRONTEND_URL=https://yourdomain.com
```

### 3. Docker Compose Produ√ß√£o
```bash
# docker-compose.prod.yml
version: '3.8'
services:
  nginx:
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/ssl:/etc/nginx/ssl
  # ... outros servi√ßos
```

## üìà Monitoramento

### M√©tricas Dispon√≠veis
- `/api/stats` - Estat√≠sticas do backend
- `/ai/stats` - Estat√≠sticas do servi√ßo AI
- Logs estruturados para an√°lise

### Health Checks
- `/api/health` - Sa√∫de do backend
- `/ai/health` - Sa√∫de do AI service
- Verifica√ß√£o autom√°tica entre servi√ßos

## üéØ Pr√≥ximos Passos

1. **Implementar autentica√ß√£o** (JWT tokens)
2. **Adicionar cache Redis** para resultados
3. **Configurar CI/CD pipeline**  
4. **Implementar rate limiting** avan√ßado
5. **Adicionar modelos AI customizados**
6. **Dashboard de analytics**
7. **API documentation** com Swagger

---

## üí° Dicas de Performance 

- **GPU**: Para m√°xima performance, configurar GPU NVIDIA
- **Caching**: Implementar cache de imagens processadas
- **CDN**: Usar CDN para arquivos est√°ticos
- **Load Balancer**: Multiple inst√¢ncias do AI service
- **Compression**: Gzip habilitado no Nginx

---

**üéâ Projeto pronto para uso!** 

O sistema est√° configurado para escalabilidade e pode processar m√∫ltiplas imagens simultaneamente com boa performance.